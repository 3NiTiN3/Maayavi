{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9240544,"sourceType":"datasetVersion","datasetId":5589636},{"sourceId":9240653,"sourceType":"datasetVersion","datasetId":5589713}],"dockerImageVersionId":30763,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Define custom datasets\nclass SymptomsDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = torch.tensor(features, dtype=torch.float32)\n        self.labels = torch.tensor(labels, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.features[idx], self.labels[idx]\n\nclass MedicineDataset(Dataset):\n    def __init__(self, features, labels):\n        self.features = torch.tensor(features, dtype=torch.float32)\n        self.labels = torch.tensor(labels, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        return self.features[idx], self.labels[idx]\n\n# Define your model with the correct number of output units\nclass YourModel(nn.Module):\n    def __init__(self, input_dim_symptoms, num_disease_classes, num_medicine_classes):\n        super(YourModel, self).__init__()\n        self.disease_fc = nn.Linear(input_dim_symptoms, num_disease_classes)\n        self.side_effects_fc = nn.Linear(input_dim_symptoms, num_medicine_classes)\n        self.uses_fc = nn.Linear(input_dim_symptoms, num_medicine_classes)\n\n    def forward(self, x):\n        disease_out = self.disease_fc(x)\n        side_effects_out = self.side_effects_fc(x)\n        uses_out = self.uses_fc(x)\n        return disease_out, side_effects_out, uses_out\n\n# Load and preprocess symptoms dataset\nwith open('/kaggle/input/symptoms/symptomsDisease246k.json', 'r') as f:\n    symptoms_data = json.load(f)\n\nsymptoms = [item['query'] for item in symptoms_data]\ndisease_labels = [item['response'] for item in symptoms_data]\n\n# Encode disease labels\nlabel_encoder = LabelEncoder()\nencoded_diseases = label_encoder.fit_transform(disease_labels)\nnum_disease_classes = len(label_encoder.classes_)\n\n# Vectorize symptoms\nvectorizer = CountVectorizer(max_features=500)\nX_symptoms = vectorizer.fit_transform(symptoms).toarray()\ninput_dim_symptoms = X_symptoms.shape[1]\n\n# Load and preprocess medicine dataset\nmedicine_df = pd.read_csv('/kaggle/input/medicine/Medicine_Details.csv')\n\n# Fill missing values\nmedicine_df['Side_effects'] = medicine_df['Side_effects'].fillna('')\nmedicine_df['Uses'] = medicine_df['Uses'].fillna('')\n\n# Extract features and labels for medicine data\nmedicine_features = medicine_df[['Side_effects', 'Uses']]\nmedicine_labels = medicine_df['Medicine Name']\n\n# Encode medicine labels\nmedicine_label_encoder = LabelEncoder()\nencoded_medicines = medicine_label_encoder.fit_transform(medicine_labels)\nnum_medicine_classes = len(medicine_label_encoder.classes_)\n\n# Vectorize medicine side effects and uses\nX_medicine_side_effects = vectorizer.transform(medicine_df['Side_effects']).toarray()\nX_medicine_uses = vectorizer.transform(medicine_df['Uses']).toarray()\nX_medicine = (X_medicine_side_effects + X_medicine_uses) / 2\n\n# Split datasets\nX_train, X_temp, y_train, y_temp = train_test_split(X_symptoms, encoded_diseases, test_size=0.2, random_state=42)\nX_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n\nX_train_medicine, X_temp_medicine, y_train_medicine, y_temp_medicine = train_test_split(X_medicine, encoded_medicines, test_size=0.2, random_state=42)\nX_valid_medicine, X_test_medicine, y_valid_medicine, y_test_medicine = train_test_split(X_temp_medicine, y_temp_medicine, test_size=0.5, random_state=42)\n\n# Create DataLoaders\ntrain_dataset = SymptomsDataset(X_train, y_train)\nvalid_dataset = SymptomsDataset(X_valid, y_valid)\ntest_dataset = SymptomsDataset(X_test, y_test)\n\ntrain_medicine_dataset = MedicineDataset(X_train_medicine, y_train_medicine)\nvalid_medicine_dataset = MedicineDataset(X_valid_medicine, y_valid_medicine)\ntest_medicine_dataset = MedicineDataset(X_test_medicine, y_test_medicine)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\ntrain_medicine_loader = DataLoader(train_medicine_dataset, batch_size=32, shuffle=True)\nvalid_medicine_loader = DataLoader(valid_medicine_dataset, batch_size=32, shuffle=False)\ntest_medicine_loader = DataLoader(test_medicine_dataset, batch_size=32, shuffle=False)\n\n# Initialize model, loss functions, and optimizer\nmodel = YourModel(input_dim_symptoms, num_disease_classes, num_medicine_classes)\ncriteria = {\n    'disease': nn.CrossEntropyLoss(),\n    'side_effects': nn.CrossEntropyLoss(),\n    'uses': nn.CrossEntropyLoss()\n}\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 50\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    for symptoms_batch, labels_disease_batch in train_loader:\n        optimizer.zero_grad()\n        disease_out, side_effects_out, uses_out = model(symptoms_batch)\n\n\n        # Compute losses\n        loss_disease = criteria['disease'](disease_out, labels_disease_batch)\n        loss_side_effects = criteria['side_effects'](side_effects_out, labels_disease_batch)  # Adjusted for correct labels\n        loss_uses = criteria['uses'](uses_out, labels_disease_batch)  # Adjusted for correct labels\n        total_loss = loss_disease + loss_side_effects + loss_uses\n        total_loss.backward()\n        optimizer.step()\n        train_loss += total_loss.item() * symptoms_batch.size(0)\n\n    train_loss /= len(train_loader.dataset)\n    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}')\n\n# Save the model\ntorch.save(model.state_dict(), 'Swastha_Model_v2.pth')\nprint('Model saved to Swastha_Model_v2.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T21:18:30.597645Z","iopub.execute_input":"2024-08-24T21:18:30.598282Z","iopub.status.idle":"2024-08-24T22:06:37.431478Z","shell.execute_reply.started":"2024-08-24T21:18:30.598237Z","shell.execute_reply":"2024-08-24T22:06:37.430381Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Epoch 1/50, Train Loss: 4.1030\nEpoch 2/50, Train Loss: 1.3111\nEpoch 3/50, Train Loss: 1.0968\nEpoch 4/50, Train Loss: 1.0147\nEpoch 5/50, Train Loss: 0.9724\nEpoch 6/50, Train Loss: 0.9480\nEpoch 7/50, Train Loss: 0.9318\nEpoch 8/50, Train Loss: 0.9202\nEpoch 9/50, Train Loss: 0.9120\nEpoch 10/50, Train Loss: 0.9060\nEpoch 11/50, Train Loss: 0.9011\nEpoch 12/50, Train Loss: 0.8969\nEpoch 13/50, Train Loss: 0.8930\nEpoch 14/50, Train Loss: 0.8907\nEpoch 15/50, Train Loss: 0.8881\nEpoch 16/50, Train Loss: 0.8863\nEpoch 17/50, Train Loss: 0.8848\nEpoch 18/50, Train Loss: 0.8831\nEpoch 19/50, Train Loss: 0.8814\nEpoch 20/50, Train Loss: 0.8805\nEpoch 21/50, Train Loss: 0.8795\nEpoch 22/50, Train Loss: 0.8786\nEpoch 23/50, Train Loss: 0.8777\nEpoch 24/50, Train Loss: 0.8773\nEpoch 25/50, Train Loss: 0.8761\nEpoch 26/50, Train Loss: 0.8752\nEpoch 27/50, Train Loss: 0.8747\nEpoch 28/50, Train Loss: 0.8740\nEpoch 29/50, Train Loss: 0.8741\nEpoch 30/50, Train Loss: 0.8730\nEpoch 31/50, Train Loss: 0.8730\nEpoch 32/50, Train Loss: 0.8722\nEpoch 33/50, Train Loss: 0.8717\nEpoch 34/50, Train Loss: 0.8714\nEpoch 35/50, Train Loss: 0.8713\nEpoch 36/50, Train Loss: 0.8708\nEpoch 37/50, Train Loss: 0.8702\nEpoch 38/50, Train Loss: 0.8702\nEpoch 39/50, Train Loss: 0.8698\nEpoch 40/50, Train Loss: 0.8696\nEpoch 41/50, Train Loss: 0.8693\nEpoch 42/50, Train Loss: 0.8696\nEpoch 43/50, Train Loss: 0.8689\nEpoch 44/50, Train Loss: 0.8689\nEpoch 45/50, Train Loss: 0.8684\nEpoch 46/50, Train Loss: 0.8685\nEpoch 47/50, Train Loss: 0.8680\nEpoch 48/50, Train Loss: 0.8681\nEpoch 49/50, Train Loss: 0.8677\nEpoch 50/50, Train Loss: 0.8676\nModel saved to Swastha_Model_v2.pth\n","output_type":"stream"}]}]}